{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSsTYZPf7N8ExzD42xEQN3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center Plant Disease Detection Using CNN</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "ObIn1BAwDbYS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_nZtVWzdQZW"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/spMohanty/PlantVillage-Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **PlantVillage-Dataset** from GitHub, This dataset contains images of various plant diseases. **54K+ images**\n",
        "\n",
        "Set the path to the root directory where the raw color images are stored."
      ],
      "metadata": {
        "id": "-yGO5xQ3Cx63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = \"/content/PlantVillage-Dataset/raw/color\""
      ],
      "metadata": {
        "id": "Iu9FXoTAgRVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the contents of the dataset directory to verify the download.\n",
        "\n",
        "`head` shows only the first few folders (the classes)"
      ],
      "metadata": {
        "id": "INjlBgSHvuXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $DATASET_ROOT | head"
      ],
      "metadata": {
        "id": "DBGwyVtLhxjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary Python libraries for deep learning and data handling.\n",
        "\n",
        "This ensures all dependencies are met for the rest of the code"
      ],
      "metadata": {
        "id": "v2ulPFBVEGZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow tensorflow-datasets matplotlib seaborn scikit-learn"
      ],
      "metadata": {
        "id": "jyiLdiAphTJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Import specific modules from Keras for building the neural network.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "2CyYDM6Mccqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "kfr6sRjGhZ01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = datagen.flow_from_directory(\n",
        "    DATASET_ROOT,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset=\"training\",\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "id": "vUfX9KdLuH_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = datagen.flow_from_directory(\n",
        "    DATASET_ROOT,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset=\"validation\",\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "id": "MuyzN0s6uKQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_gen.class_indices)\n",
        "print(\"Classes:\", train_gen.class_indices)"
      ],
      "metadata": {
        "id": "jYv23MWfhjz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model (Transfer Learning)"
      ],
      "metadata": {
        "id": "L72tyLFiibF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a pre-trained EfficientNetB0 model.\n",
        "\n",
        "`include_top=False` means we are only using the feature-extracting base,not the final classification layers.\n",
        "\n",
        "Freeze the base model's layers so their weights are not updated during training."
      ],
      "metadata": {
        "id": "Y1UY0Hr_FKbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base_model.trainable = False  # Freeze base initially\n"
      ],
      "metadata": {
        "id": "t-4gDJO2z-7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a GlobalAveragePooling2D layer on top of the base model's output.\n",
        "\n",
        "This averages the feature maps, preparing the data for the final classification layers."
      ],
      "metadata": {
        "id": "nSiIhJ6A0GWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)"
      ],
      "metadata": {
        "id": "-K_XXRv1-PZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a BatchNormalization layer to stabilize and speed up training."
      ],
      "metadata": {
        "id": "5QNutI5lFvZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Normalisation\n",
        "x = tf.keras.layers.BatchNormalization()(x)"
      ],
      "metadata": {
        "id": "Rx5dkQJX-Cgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a Dropout layer to randomly ignore some neurons, which helps prevent overfitting."
      ],
      "metadata": {
        "id": "ozFw7mHWFz5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout for regularization\n",
        "x = tf.keras.layers.Dropout(0.4)(x)"
      ],
      "metadata": {
        "id": "fisfqhra0WpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a fully connected (Dense) layer with 256 neurons and ReLU activation."
      ],
      "metadata": {
        "id": "LWF3kiWtF7fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)"
      ],
      "metadata": {
        "id": "J0oyR-Af-RD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add another BatchNormalization layer."
      ],
      "metadata": {
        "id": "EdvZdk_SbHh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Normalisation after dense layer\n",
        "x = tf.keras.layers.BatchNormalization()(x)"
      ],
      "metadata": {
        "id": "FcSXVerOJlDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "f8YLa65u4Jnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new Sequential model, which stacks layers one after another, Add convolutional layers and pooling layers to extract features from images, more complex features.\n",
        "\n",
        "Flatten the output of the convolutional layers into a 1D vector, Add a fully connected layer with 128 neurons\n",
        "\n",
        "\n",
        "Add the final output layer with `num_classes` neurons for classification."
      ],
      "metadata": {
        "id": "xfznRYSmbQ3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "DypDswjw4P07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model"
      ],
      "metadata": {
        "id": "xsHzn7Oa4UkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "__2mQPn44T-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation (Second, more detailed attempt)"
      ],
      "metadata": {
        "id": "WZJAXjvVb3Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "Z6ReO_o2um6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Create train/val directories\n",
        "train_dir = \"/content/PlantVillage-Dataset/train\"\n",
        "val_dir = \"/content/PlantVillage-Dataset/val\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "j5POp_2q1KDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over each class folder\n",
        "dataset_dir = \"/content/PlantVillage-Dataset/raw/color\"\n",
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "        split = int(len(images) * 0.8)  # 80% train, 20% val\n",
        "\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in images[:split]:\n",
        "            shutil.copy(os.path.join(class_path, img), train_class_dir)\n",
        "        for img in images[split:]:\n",
        "            shutil.copy(os.path.join(class_path, img), val_class_dir)"
      ],
      "metadata": {
        "id": "crV3yYP-1lnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage-Dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "j3YMu9MGuq1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage-Dataset/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "uckFTZQW2Aw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // val_generator.batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "xQ3s2g7lumxF",
        "outputId": "b082b3ed-e6d8-4764-c5b9-6716317d8112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m 136/1357\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01:21\u001b[0m 3s/step - accuracy: 0.0869 - loss: 5.0509"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "di5G2PLI4ZU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aimbJQqZPckh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mwh_QrlJUpSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained Keras model\n",
        "model.save('/content/crop_disease_model.h5')\n",
        "print(\"Model saved as crop_disease_model.h5\")"
      ],
      "metadata": {
        "id": "RT-j7NMWYG-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l1IUiFi2Zp8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder inside Google Drive\n",
        "save_path = \"/content/drive/MyDrive/CropDiseaseModel\"\n",
        "import os\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save Keras model (.h5)\n",
        "model.save(f\"{save_path}/crop_disease_model.h5\")\n",
        "\n",
        "# Save TFLite model (.tflite)\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open(f\"{save_path}/crop_disease_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"✅ Model saved to Google Drive at:\", save_path)\n"
      ],
      "metadata": {
        "id": "vsiL5ts9aK5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62KNlV3FaLbm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}